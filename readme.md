# ğŸ¦µ **Kneez App â€“ Functional Specification (MVP)**

## ğŸ“Œ Purpose
Kneez is a mobile app that provides **immediate pain relief for knee pain** using **voice/text interaction, anatomical diagrams, and personalized movement correction tips**. It uses conversational AI and NLP to triage symptoms and deliver biomechanical interventions.

---

## 1. ğŸ§­ **Core User Flow**

### 1.1 Initial Interaction
- App opens with prompt: â€œHi, whatâ€™s bothering you?â€
- Users long-press **voice button** or toggle to **text input** to describe:
  - Symptom
  - Pain trigger (e.g., squatting, stairs)
  - Additional context (optional)

### 1.2 Pain Location Selection
- User interacts with **3D knee diagram**:
  - Two knees shown (left + right), clearly labeled
  - Users **rotate** the model freely (pan/drag)
  - Users can **tap one area per knee**, maximum 2 total
- App asks for **confirmation** of tapped area using **layman terms**
  - e.g., â€œYou tapped the inside of your right knee, slightly below the kneecap. Is this where you feel your pain?â€

### 1.3 Movement Tip Delivery
- If sufficient info is available:
  - App delivers a **captioned video** + **audio instructions** (unless muted)
  - Tips are selected via semantic matching: `pain location` + `activity trigger`
- If info is **insufficient**:
  - App dynamically asks for missing fields (pain type, duration, etc.)
- After tip is shown:
  - User is polled: â€œHow do your knees feel now?â€
  - Options: ğŸ˜ / ğŸ™‚ / ğŸ˜ / ğŸ™ / ğŸ˜¢ (smiley face feedback scale)

### 1.4 Iteration & Escalation
- If ğŸ˜ or ğŸ™‚:
  - Show success message and advice on how to integrate the tip in daily movement
  - Inform the user that **strengthening/stretching features** are coming soon
- If ğŸ˜, ğŸ™, or ğŸ˜¢:
  - Offer a second tip or ask for more symptom data
  - After 3 failed attempts:
    - App apologizes
    - Collects a full case (all fields)
    - Tells user a human review will occur

---

## 2. ğŸ§  NLP & Data Extraction Pipeline

### 2.1 Required Fields (every case)
- **Pain Location** (via tap + text)
- **Triggering Activity** (e.g., squatting)
- **Laterality** (left, right, both)

### 2.2 Optional Fields (asked when needed)
- Pain type (sharp, dull, burningâ€¦)
- Pain severity (inferred from emoji feedback or asked directly)
- Duration
- Context (e.g., â€œafter tennisâ€)

App will prompt user for more details if confidence is low or no tip match is found.

---

## 3. ğŸ¯ Movement Tip Matching

### Matching Logic:
- **Exact Match Priority:** Pain location + activity trigger
- **Fallback:** Closest match (based on similarity scores)
- **Last resort:** General tip for that activity

### Always followed by:
- Poll asking: Did this help? (emoji rating)
- Results used to train feedback model (build success rate data)

---

## 4. ğŸ—‚ï¸ Case Management

### Each session is stored as a **structured case**:
```json
{
  "case_id": "CASE00123",
  "user_id": "USER048",
  "input_symptoms": "My knee hurts when I walk downstairs",
  "pain_location": "inferior patella",
  "trigger": "stairs down",
  "laterality": "right",
  "movement_tips_shown": [
    {
      "tip_id": "TIP0012",
      "user_feedback": "neutral"
    }
  ],
  "status": "resolved",
  "timestamp": "2025-04-28T18:00:00Z"
}
```

### Features:
- Stored under user profile
- Viewable in **read-only session history**
- Sharable via link (read-only web view; future version only)

---

## 5. ğŸ§© Movement Tip Schema

Each tip includes:
```json
{
  "id": "TIP0012",
  "anatomical_targets": ["patellar tendon"],
  "triggering_activities": ["squatting"],
  "tip_content": {
    "video_url": "...",
    "caption_text": "...",
    "audio_script": "..."
  },
  "contraindications": ["Not for meniscal tears"],
  "feedback_log": [
    {
      "case_id": "CASE034",
      "outcome": "positive",
      "user_rating": ":)"
    }
  ]
}
```

---

## 6. ğŸ“² User Interface

### Home Screen
- Heading: â€œHi, whatâ€™s bothering you?â€
- Voice button (long-press to record)
- Keyboard toggle (doubles as mute button)
- 3D Knee model (rotate + tap)

### Tip Display
- Video with captions
- Audio instruction unless muted
- Emoji-based feedback poll

### History Screen
- List of past cases (summary view)
- Tap to view full case (read-only)

---

## 7. ğŸ” Data Handling & Learning
- User data is stored securely (e.g., Firebase, Supabase)
- Emoji feedback & tip outcomes are stored to train future tip rankings
- NLP fields stored as structured JSON per case
- User data anonymized for research/model improvement

---

## 8. âŒ Out-of-Scope (MVP)
- Strengthening/stretching programs (planned for later)
- PDF reports / live dashboards for doctors
- User-generated notes or journaling
- Multi-language support

---
